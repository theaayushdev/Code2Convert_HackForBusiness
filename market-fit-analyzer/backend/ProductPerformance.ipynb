{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0732b060-071c-4de5-93e7-86108aa53836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f10850-d739-49f7-b1c7-6121acfe2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd53daea-de17-49e2-b31e-7e29834c06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(transactions_csv, products_csv, shops_csv):\n",
    "    \"\"\"Load data from CSV files and combine them\"\"\"\n",
    "    print(\"Loading CSV files...\")\n",
    "    \n",
    "    # Load the three tables\n",
    "    transactions = pd.read_csv(transactions_csv)\n",
    "    products = pd.read_csv(products_csv)\n",
    "    shops = pd.read_csv(shops_csv)\n",
    "    \n",
    "    print(f\"Loaded {len(transactions)} transactions\")\n",
    "    print(f\"Loaded {len(products)} products\")\n",
    "    print(f\"Loaded {len(shops)} shops\")\n",
    "    \n",
    "    # Combine all data\n",
    "    data = transactions.merge(products, on='product_id', how='left')\n",
    "    data = data.merge(shops, on='shop_id', how='left')\n",
    "    \n",
    "    # Filter only sales transactions\n",
    "    if 'transaction_type' in data.columns:\n",
    "        data = data[data['transaction_type'] == 'SALE']\n",
    "    \n",
    "    # Convert transaction_time to datetime\n",
    "    data['transaction_time'] = pd.to_datetime(data['transaction_time'])\n",
    "    data = data.sort_values('transaction_time')\n",
    "    \n",
    "    print(f\"Combined data: {len(data)} sales records\")\n",
    "    print(f\"Date range: {data['transaction_time'].min()} to {data['transaction_time'].max()}\")\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959c685-0fe8-4dbe-931c-40db9ec9a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_monthly_data(data):\n",
    "    \"\"\"Convert daily transactions to monthly sales data\"\"\"\n",
    "    print(\"Preparing monthly sales data...\")\n",
    "    \n",
    "    # Create year-month column\n",
    "    data['year_month'] = data['transaction_time'].dt.to_period('M')\n",
    "    \n",
    "    # Group by product, shop, and month to get monthly totals\n",
    "    monthly_sales = data.groupby(['product_id', 'shop_id', 'year_month']).agg({\n",
    "        'quantity': 'sum',\n",
    "        'total_amount': 'sum',\n",
    "        'unit_price': 'mean',\n",
    "        'product_name': 'first',\n",
    "        'category': 'first',\n",
    "        'city': 'first',\n",
    "        'standard_price': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    monthly_sales.columns = ['product_id', 'shop_id', 'year_month', 'monthly_quantity', \n",
    "                            'monthly_revenue', 'avg_price', 'product_name', 'category', \n",
    "                            'city', 'standard_price']\n",
    "    \n",
    "    monthly_sales = monthly_sales.sort_values(['product_id', 'shop_id', 'year_month'])\n",
    "    \n",
    "    print(f\"Created {len(monthly_sales)} monthly sales records\")\n",
    "    return monthly_sales\n",
    "\n",
    "def create_features(monthly_data):\n",
    "    \"\"\"Create features for prediction\"\"\"\n",
    "    print(\"Creating features...\")\n",
    "    \n",
    "    # Convert year_month to datetime\n",
    "    monthly_data['month_date'] = monthly_data['year_month'].dt.to_timestamp()\n",
    "    monthly_data['month'] = monthly_data['month_date'].dt.month\n",
    "    monthly_data['year'] = monthly_data['month_date'].dt.year\n",
    "    \n",
    "    # Create lag features (previous months' sales)\n",
    "    monthly_data['last_month_qty'] = monthly_data.groupby(['product_id', 'shop_id'])['monthly_quantity'].shift(1)\n",
    "    monthly_data['last_2_months_qty'] = monthly_data.groupby(['product_id', 'shop_id'])['monthly_quantity'].shift(2)\n",
    "    monthly_data['last_3_months_qty'] = monthly_data.groupby(['product_id', 'shop_id'])['monthly_quantity'].shift(3)\n",
    "    \n",
    "    # Create average of last 3 months\n",
    "    monthly_data['avg_last_3_months'] = (\n",
    "        monthly_data['last_month_qty'] + \n",
    "        monthly_data['last_2_months_qty'] + \n",
    "        monthly_data['last_3_months_qty']\n",
    "    ) / 3\n",
    "    \n",
    "    # Create trend feature\n",
    "    monthly_data['trend'] = monthly_data['last_month_qty'] - monthly_data['last_2_months_qty']\n",
    "    \n",
    "    # Price difference from standard\n",
    "    monthly_data['price_difference'] = monthly_data['avg_price'] - monthly_data['standard_price']\n",
    "    \n",
    "    # Seasonal features\n",
    "    monthly_data['is_holiday_month'] = monthly_data['month'].isin([11, 12, 1, 4, 10]).astype(int)\n",
    "    monthly_data['is_summer'] = monthly_data['month'].isin([3, 4, 5, 6]).astype(int)\n",
    "    \n",
    "    # Convert categorical variables to numbers\n",
    "    monthly_data['category_code'] = pd.Categorical(monthly_data['category']).codes\n",
    "    monthly_data['city_code'] = pd.Categorical(monthly_data['city']).codes\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    monthly_data = monthly_data.dropna(subset=['last_month_qty', 'last_2_months_qty', 'last_3_months_qty'])\n",
    "    \n",
    "    print(f\"Final dataset: {len(monthly_data)} records with features\")\n",
    "    return monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f539a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(monthly_data):\n",
    "    \"\"\"Train the prediction model\"\"\"\n",
    "    print(\"Training model...\")\n",
    "    \n",
    "    # Select features for training\n",
    "    feature_columns = [\n",
    "        'last_month_qty', 'last_2_months_qty', 'last_3_months_qty',\n",
    "        'avg_last_3_months', 'trend', 'month', 'avg_price',\n",
    "        'standard_price', 'price_difference', 'is_holiday_month',\n",
    "        'is_summer', 'category_code', 'city_code'\n",
    "    ]\n",
    "    \n",
    "    # Prepare training data\n",
    "    X = monthly_data[feature_columns]\n",
    "    y = monthly_data['monthly_quantity']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Test model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model trained successfully!\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"Root Mean Square Error: {rmse:.2f}\")\n",
    "    print(f\"Root Mean Square Error: {accuracy:.2f}\")\n",
    "    # Show feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nMost Important Features:\")\n",
    "    print(importance.head(6))\n",
    "    \n",
    "    return model, feature_columns, {'mae': mae, 'rmse': rmse, 'accuracy': accuracy, 'feature_importance': importance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92793fc4-2b4d-4bb3-8690-a29e0f098992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_month(model, feature_columns, monthly_data, product_id, shop_id):\n",
    "    \"\"\"Predict next month's sales for a specific product and shop\"\"\"\n",
    "    \n",
    "    # Get data for the specific product-shop combination\n",
    "    product_data = monthly_data[\n",
    "        (monthly_data['product_id'] == product_id) & \n",
    "        (monthly_data['shop_id'] == shop_id)\n",
    "    ].copy()\n",
    "    \n",
    "    if len(product_data) == 0:\n",
    "        return None, \"No historical data found for this product-shop combination\"\n",
    "    \n",
    "    # Get the most recent record\n",
    "    latest_record = product_data.sort_values('year_month').iloc[-1]\n",
    "    \n",
    "    # Create features for prediction\n",
    "    features = {\n",
    "        'last_month_qty': latest_record['monthly_quantity'],\n",
    "        'last_2_months_qty': latest_record['last_month_qty'],\n",
    "        'last_3_months_qty': latest_record['last_2_months_qty'],\n",
    "        'avg_last_3_months': latest_record['avg_last_3_months'],\n",
    "        'trend': latest_record['trend'],\n",
    "        'month': (latest_record['month'] % 12) + 1,  # Next month\n",
    "        'avg_price': latest_record['avg_price'],\n",
    "        'standard_price': latest_record['standard_price'],\n",
    "        'price_difference': latest_record['price_difference'],\n",
    "        'is_holiday_month': ((latest_record['month'] % 12) + 1) in [11, 12, 1, 4, 10],\n",
    "        'is_summer': ((latest_record['month'] % 12) + 1) in [3, 4, 5, 6],\n",
    "        'category_code': latest_record['category_code'],\n",
    "        'city_code': latest_record['city_code']\n",
    "    }\n",
    "    \n",
    "    # Convert to DataFrame for prediction\n",
    "    X_pred = pd.DataFrame([features])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(X_pred)[0]\n",
    "    prediction = max(0, prediction)  # Ensure non-negative\n",
    "    \n",
    "    return round(prediction, 2), \"Success\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3210f75d-c3c3-49e6-a434-0c28bf904523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_predictions(model, feature_columns, monthly_data):\n",
    "    \"\"\"Get predictions for all product-shop combinations\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # Get unique product-shop combinations\n",
    "    combinations = monthly_data[['product_id', 'shop_id', 'product_name', 'city']].drop_duplicates()\n",
    "    \n",
    "    for _, row in combinations.iterrows():\n",
    "        prediction, status = predict_next_month(model, feature_columns, monthly_data, \n",
    "                                              row['product_id'], row['shop_id'])\n",
    "        \n",
    "        predictions.append({\n",
    "            'product_id': row['product_id'],\n",
    "            'product_name': row['product_name'],\n",
    "            'shop_id': row['shop_id'],\n",
    "            'city': row['city'],\n",
    "            'predicted_quantity': prediction,\n",
    "            'status': status\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9064a991-fb72-42a5-a663-2b11e28499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sales(transactions_csv, products_csv, shops_csv):\n",
    "    \"\"\"Main function to predict sales from CSV files\"\"\"\n",
    "    \n",
    "    # Load and prepare data\n",
    "    data = load_data(transactions_csv, products_csv, shops_csv)\n",
    "    monthly_data = prepare_monthly_data(data)\n",
    "    monthly_data = create_features(monthly_data)\n",
    "    \n",
    "    # Train model\n",
    "    model, feature_columns, metrics = train_model(monthly_data)\n",
    "    \n",
    "    # Get all predictions\n",
    "    predictions = get_all_predictions(model, feature_columns, monthly_data)\n",
    "    \n",
    "    return predictions, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e975189-a846-45e3-a112-9897bb28aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_specific_product(transactions_csv, products_csv, shops_csv, product_id, shop_id):\n",
    "    \"\"\"Predict for a specific product and shop\"\"\"\n",
    "    \n",
    "    # Load and prepare data\n",
    "    data = load_data(transactions_csv, products_csv, shops_csv)\n",
    "    monthly_data = prepare_monthly_data(data)\n",
    "    monthly_data = create_features(monthly_data)\n",
    "    \n",
    "    # Train model\n",
    "    model, feature_columns, _ = train_model(monthly_data)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction, status = predict_next_month(model, feature_columns, monthly_data, product_id, shop_id)\n",
    "    \n",
    "    return prediction, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0db14a8b-fdb2-4c36-9ae5-b01f0e655480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_predictions_file(filename=None):\n",
    "    \"\"\"View the most recent predictions file\"\"\"\n",
    "    import glob\n",
    "    \n",
    "    if filename is None:\n",
    "        # Find the most recent predictions file\n",
    "        files = glob.glob(\"sales_predictions_*.csv\")\n",
    "        if not files:\n",
    "            print(\"No predictions files found!\")\n",
    "            return\n",
    "        filename = max(files)  # Most recent file\n",
    "    \n",
    "    try:\n",
    "        predictions = pd.read_csv(filename)\n",
    "        print(f\"\\n=== VIEWING PREDICTIONS FROM {filename} ===\")\n",
    "        display_predictions_summary(predictions)\n",
    "        return predictions\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found!\")\n",
    "        return None\n",
    "    \"\"\"Generate sample CSV files for testing\"\"\"\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    print(\"Creating sample transactions.csv...\")\n",
    "    # Sample transactions\n",
    "    transactions = []\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    \n",
    "    for i in range(1000):\n",
    "        date = start_date + timedelta(days=random.randint(0, 400))\n",
    "        transactions.append({\n",
    "            'transaction_id': i + 1,\n",
    "            'product_id': random.randint(1, 20),\n",
    "            'shop_id': random.randint(1, 5),\n",
    "            'transaction_time': date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'quantity': random.randint(1, 10),\n",
    "            'unit_price': round(random.uniform(10, 100), 2),\n",
    "            'total_amount': 0,  # Will calculate\n",
    "            'transaction_type': 'SALE'\n",
    "        })\n",
    "    \n",
    "    # Calculate total_amount\n",
    "    for t in transactions:\n",
    "        t['total_amount'] = t['quantity'] * t['unit_price']\n",
    "    \n",
    "    pd.DataFrame(transactions).to_csv('transactions.csv', index=False)\n",
    "    \n",
    "    print(\"Creating sample products.csv...\")\n",
    "    # Sample products\n",
    "    categories = ['Electronics', 'Clothing', 'Food', 'Books', 'Home']\n",
    "    products = []\n",
    "    for i in range(1, 21):\n",
    "        products.append({\n",
    "            'product_id': i,\n",
    "            'product_name': f'Product {i}',\n",
    "            'category': random.choice(categories),\n",
    "            'standard_price': round(random.uniform(15, 90), 2)\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(products).to_csv('products.csv', index=False)\n",
    "    \n",
    "    print(\"Creating sample shops.csv...\")\n",
    "    # Sample shops\n",
    "    cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "    shops = []\n",
    "    for i in range(1, 6):\n",
    "        shops.append({\n",
    "            'shop_id': i,\n",
    "            'shop_name': f'Shop {i}',\n",
    "            'city': cities[i-1],\n",
    "            'state': 'State'\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(shops).to_csv('shops.csv', index=False)\n",
    "    print(\"Sample data files created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00925319-82b1-4427-8455-030ac891ca43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREDICTING SALES FOR ALL PRODUCTS ===\n",
      "Loading CSV files...\n",
      "Loaded 10000 transactions\n",
      "Loaded 200 products\n",
      "Loaded 50 shops\n",
      "Combined data: 10000 sales records\n",
      "Date range: 2023-01-01 00:00:00 to 2023-12-31 00:00:00\n",
      "Preparing monthly sales data...\n",
      "Created 9625 monthly sales records\n",
      "Creating features...\n",
      "Final dataset: 141 records with features\n",
      "Training model...\n",
      "Model trained successfully!\n",
      "Mean Absolute Error: 2.59\n",
      "Root Mean Square Error: 3.10\n",
      "\n",
      "Most Important Features:\n",
      "              feature  importance\n",
      "8    price_difference    0.154062\n",
      "4               trend    0.111852\n",
      "11      category_code    0.106201\n",
      "3   avg_last_3_months    0.102361\n",
      "6           avg_price    0.085630\n",
      "2   last_3_months_qty    0.081210\n",
      "\n",
      "=== DETAILED PREDICTIONS SUMMARY ===\n",
      "\n",
      "TOP 20 HIGHEST PREDICTED SALES:\n",
      " 1. Lays Sna60           | Shop: 39 | City: Bhaktapur    | Predicted:   9.01 units\n",
      " 2. Lux Per36            | Shop: 41 | City: Bhaktapur    | Predicted:   8.97 units\n",
      " 3. Wai Wai Sna13        | Shop: 14 | City: Lalitpur     | Predicted:   8.35 units\n",
      " 4. Pringles Sna93       | Shop: 46 | City: Lalitpur     | Predicted:   8.14 units\n",
      " 5. Coca-Cola Bev80      | Shop: 28 | City: Kathmandu    | Predicted:   7.89 units\n",
      " 6. Nestle Bev16         | Shop: 42 | City: Bhaktapur    | Predicted:   7.81 units\n",
      " 7. Nestle Bev3          | Shop: 28 | City: Kathmandu    | Predicted:   7.79 units\n",
      " 8. Red Bull Bev29       | Shop: 25 | City: Lalitpur     | Predicted:   7.76 units\n",
      " 9. Pepsi Bev113         | Shop:  7 | City: Kathmandu    | Predicted:   7.68 units\n",
      "10. Pepsi Bev31          | Shop: 29 | City: Biratnagar   | Predicted:   7.66 units\n",
      "11. Lays Sna60           | Shop: 48 | City: Biratnagar   | Predicted:   7.60 units\n",
      "12. Coca-Cola Bev106     | Shop: 44 | City: Biratnagar   | Predicted:   7.57 units\n",
      "13. Kurkure Sna167       | Shop: 12 | City: Kathmandu    | Predicted:   7.54 units\n",
      "14. Coca-Cola Bev65      | Shop: 40 | City: Biratnagar   | Predicted:   7.53 units\n",
      "15. Lays Sna180          | Shop: 35 | City: Lalitpur     | Predicted:   7.50 units\n",
      "16. Pepsi Bev71          | Shop: 40 | City: Biratnagar   | Predicted:   7.45 units\n",
      "17. Pepsi Bev47          | Shop: 37 | City: Lalitpur     | Predicted:   7.44 units\n",
      "18. Lays Sna105          | Shop: 13 | City: Kathmandu    | Predicted:   7.42 units\n",
      "19. Wai Wai Sna149       | Shop: 38 | City: Bhaktapur    | Predicted:   7.42 units\n",
      "20. Pepsi Bev1           | Shop: 33 | City: Lalitpur     | Predicted:   7.39 units\n",
      "\n",
      "=== PREDICTIONS BY CITY ===\n",
      "            Products  Total_Predicted  Avg_Predicted\n",
      "city                                                \n",
      "Bhaktapur         28           182.55           6.52\n",
      "Biratnagar        27           169.92           6.29\n",
      "Kathmandu         26           163.25           6.28\n",
      "Lalitpur          22           132.97           6.04\n",
      "Pokhara           14            80.65           5.76\n",
      "\n",
      "=== TOP 15 PRODUCTS BY TOTAL PREDICTED SALES ===\n",
      "Lays Sna60                | Total Predicted:  29.51 units\n",
      "Pringles Sna94            | Total Predicted:  18.00 units\n",
      "Himalaya Per168           | Total Predicted:  16.57 units\n",
      "Dove Per56                | Total Predicted:  15.54 units\n",
      "Pringles Sna93            | Total Predicted:  15.40 units\n",
      "Vim Hou109                | Total Predicted:  15.19 units\n",
      "Pepsi Bev113              | Total Predicted:  14.85 units\n",
      "Nestle Bev3               | Total Predicted:  14.79 units\n",
      "Lays Sna180               | Total Predicted:  14.70 units\n",
      "Nestle Dai146             | Total Predicted:  14.02 units\n",
      "Himalaya Per32            | Total Predicted:  13.31 units\n",
      "Surf Excel Hou121         | Total Predicted:  13.19 units\n",
      "Lays Sna64                | Total Predicted:  11.74 units\n",
      "Dove Per140               | Total Predicted:  11.62 units\n",
      "Himalaya Per160           | Total Predicted:  10.72 units\n",
      "\n",
      "=== PREDICTIONS SAVED ===\n",
      "File: sales_predictions_20250623_091317.csv\n",
      "Total predictions: 117\n",
      "Model accuracy - MAE: 2.59, RMSE: 3.10\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total Products: 92\n",
      "Total Shops: 47\n",
      "Average Predicted Quantity: 6.23\n",
      "Max Predicted Quantity: 9.01\n",
      "Min Predicted Quantity: 3.72\n",
      "\n",
      "Top 10 Predictions:\n",
      "Product: Pepsi Bev1 | Shop: 33 | City: Lalitpur | Predicted: 7.39 units\n",
      "Product: Nestle Bev3 | Shop: 28 | City: Kathmandu | Predicted: 7.79 units\n",
      "Product: Nestle Bev3 | Shop: 37 | City: Lalitpur | Predicted: 7.0 units\n",
      "Product: Nestle Bev4 | Shop: 45 | City: Bhaktapur | Predicted: 7.18 units\n",
      "Product: Pepsi Bev5 | Shop: 43 | City: Kathmandu | Predicted: 6.42 units\n",
      "Product: Surf Excel Hou6 | Shop: 6 | City: Biratnagar | Predicted: 5.25 units\n",
      "Product: Lays Sna8 | Shop: 34 | City: Biratnagar | Predicted: 6.11 units\n",
      "Product: Coca-Cola Bev10 | Shop: 41 | City: Bhaktapur | Predicted: 6.89 units\n",
      "Product: Wai Wai Sna13 | Shop: 14 | City: Lalitpur | Predicted: 8.35 units\n",
      "Product: Nestle Bev16 | Shop: 42 | City: Bhaktapur | Predicted: 7.81 units\n",
      "\n",
      "=== USAGE EXAMPLES ===\n",
      "To view saved predictions file:\n",
      "predictions_df = view_predictions_file()\n",
      "\n",
      "To make predictions without saving:\n",
      "predictions, metrics = predict_sales('transactions.csv', 'products.csv', 'shops.csv', save_to_file=False)\n",
      "\n",
      "To predict for specific product:\n",
      "prediction, status = predict_for_specific_product('transactions.csv', 'products.csv', 'shops.csv', product_id=123, shop_id=45)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Check if CSV files exist locally first\n",
    "    import os\n",
    "    csv_files = [\"transactions.csv\", \"products.csv\", \"shops.csv\"]\n",
    "    files_exist = all(os.path.exists(file) for file in csv_files)\n",
    "    \n",
    "    if files_exist:\n",
    "        try:\n",
    "            print(\"=== PREDICTING SALES FOR ALL PRODUCTS ===\")\n",
    "            predictions, metrics = predict_sales(\"transactions.csv\", \"products.csv\", \"shops.csv\")\n",
    "            \n",
    "            # Display detailed summary\n",
    "            display_predictions_summary(predictions)\n",
    "\n",
    "            save_predictions_to_file(predictions, metrics)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"\\nTop 10 Predictions:\")\n",
    "            top_predictions = predictions.head(10)\n",
    "            for _, row in top_predictions.iterrows():\n",
    "                print(f\"Product: {row['product_name']} | Shop: {row['shop_id']} | \"\n",
    "                      f\"City: {row['city']} | Predicted: {row['predicted_quantity']} units\")\n",
    "            \n",
    "            print(f\"\\n=== USAGE EXAMPLES ===\")\n",
    "            print(\"To view saved predictions file:\")\n",
    "            print(\"predictions_df = view_predictions_file()\")\n",
    "            print(\"\\nTo make predictions without saving:\")\n",
    "            print(\"predictions, metrics = predict_sales('transactions.csv', 'products.csv', 'shops.csv', save_to_file=False)\")\n",
    "            print(\"\\nTo predict for specific product:\")\n",
    "            print(\"prediction, status = predict_for_specific_product('transactions.csv', 'products.csv', 'shops.csv', product_id=123, shop_id=45)\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing files: {e}\")\n",
    "    \n",
    "    else:\n",
    "        # Generate sample data if files don't exist\n",
    "        print(\"CSV files not found. Generating sample data...\")\n",
    "        generate_sample_data()\n",
    "        \n",
    "        print(\"Sample data created! Now running predictions...\")\n",
    "        try:\n",
    "            predictions, metrics = predict_sales(\"transactions.csv\", \"products.csv\", \"shops.csv\")\n",
    "            \n",
    "            print(\"\\nTop 10 Predictions:\")\n",
    "            top_predictions = predictions.head(10)\n",
    "            for _, row in top_predictions.iterrows():\n",
    "                print(f\"Product: {row['product_name']} | Shop: {row['shop_id']} | \"\n",
    "                      f\"City: {row['city']} | Predicted: {row['predicted_quantity']} units\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f52f1b1-bccf-4b1b-9988-ad0427694179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No predictions files found!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598054c-47d3-4359-a6ed-9b3fa8b39d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
